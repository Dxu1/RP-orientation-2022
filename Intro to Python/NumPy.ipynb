{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e779de8",
   "metadata": {},
   "source": [
    "# Intro to Python - Part 2\n",
    "\n",
    "## Outline\n",
    "\n",
    "- NumPy\n",
    "    - Creata a NumPy array\n",
    "    - Array operation\n",
    "- Object-oriented Programming (OOP)\n",
    "    - What is OOP\n",
    "    - Application\n",
    "- Parallel Computing\n",
    "    - Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60aa1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import multiprocess\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196a43f",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "`NumPy` is a library that supplies two major features. \n",
    " - better support for large multi-dimensional arrays. \n",
    " - high-level mathematical functions that operate on them.\n",
    " \n",
    "In summary, `NumPy` (+`Matplotlib`) allows you to use Matlab in Python.\n",
    "\n",
    "We will illustrate `NumPy` using an example in Stock et al. (2002) that shows how IV estimates might be biased toward the OLS estimates when the instrument is weak. Consider the following data generating process\n",
    "$$\\begin{aligned}\n",
    "    D_i &= \\gamma Z_i + V_i,  \\\\\n",
    "    Y_i &= \\beta D_i + U_i, \\\\\n",
    "    (U_i, V_i) &\\sim Normal(0, \\Omega), \\\\\n",
    "    \\Omega &= \\begin{pmatrix}\n",
    "        1 & \\rho \\\\\n",
    "        \\rho & 1\n",
    "    \\end{pmatrix} \\\\\n",
    "    Z_i &\\sim Normal(0, \\sigma^2)\n",
    "\\end{aligned}$$\n",
    "where $\\beta = 0$, $\\sigma = 1$, and $\\rho = 0.99$.\n",
    "\n",
    "Note that this is a classical IV regression, where we are interested in estimating $\\beta$ and we instrument $D$ with $Z$. The purpose of this simulation is to show how the distribution of $\\hat{\\beta}$ changes as we alter the magnitude of $\\gamma$, (i.e. the strength of the first stage). \n",
    "\n",
    "We will draw $N = 1,000$ observations from the data generating process and run simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef7e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "beta = 0\n",
    "sigma = 1\n",
    "rho = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c964778",
   "metadata": {},
   "source": [
    "### Create a NumPy Array\n",
    "\n",
    "Our first step is to construct all the relevant matrices. This part is very similar to Robin's lecture on Intro to Matlab. There are three common ways to create a numpy array.\n",
    "\n",
    "1. Create an array from a list: `A = np.array(list)`\n",
    "2. Create an array of 0s / 1s: `B = np.zeros((nrow, ncol))` or `C = np.ones((nrow, ncol))` \n",
    "3. Create a random array: `C = np.random.rand(nrow, ncol)` or other functions from `np.random`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3efb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4],[5,6]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230ef831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "B1 = np.zeros((2, 3))\n",
    "B2 = np.ones((2, 3))\n",
    "print(B1)\n",
    "print(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f54b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37454012],\n",
       "       [0.95071431],\n",
       "       [0.73199394],\n",
       "       [0.59865848]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.random.rand(4, 1)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70b671",
   "metadata": {},
   "source": [
    "Access element in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40b0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[2 4 6]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(A[0,:]) #i-th row\n",
    "print(A[:,1]) #j-th column\n",
    "print(A[0,1]) # (i,j) coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f0274",
   "metadata": {},
   "source": [
    "Get the dimension and number of elements of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c477f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(A.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f012a39",
   "metadata": {},
   "source": [
    "Now, let's construct the arrays in our example. Recall that \n",
    "$$\\begin{aligned}\n",
    "    D_i &= \\gamma Z_i + V_i,  \\\\\n",
    "    Y_i &= \\beta D_i + U_i, \\\\\n",
    "    (U_i, V_i) &\\sim Normal(0, \\Omega), \\\\\n",
    "    \\Omega &= \\begin{pmatrix}\n",
    "        1 & \\rho \\\\\n",
    "        \\rho & 1\n",
    "    \\end{pmatrix} \\\\\n",
    "    Z_i &\\sim Normal(0, \\sigma^2)\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63bc13bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.99],\n",
       "       [0.99, 1.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma = np.array([[1, rho], [rho, 1]])\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2449c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.random.normal(0, sigma, N)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3151e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "UV = np.random.multivariate_normal([0, 0], Sigma, N)\n",
    "print(UV.shape)\n",
    "U = UV[:,0]\n",
    "V = UV[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31238e8",
   "metadata": {},
   "source": [
    "### NumPy Array Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49eb02",
   "metadata": {},
   "source": [
    "Scaler multiplication (`*`) and addition (`+`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7edbf4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4]\n",
      " [6 8]]\n",
      "[[2 2]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[1,0],[0,1]])\n",
    "print(2 * A)\n",
    "print(A + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4ebcf",
   "metadata": {},
   "source": [
    "Element-wise multiplication (`*`) and Matrix multiplication `@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d682345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(A * B)\n",
    "print(A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491128d1",
   "metadata": {},
   "source": [
    "Sum of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820b56e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dea358",
   "metadata": {},
   "source": [
    "Get the transpose a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ec9d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e4e07",
   "metadata": {},
   "source": [
    "Other useful operation from linear algebra (`np.linalg`): norm, determinant, inverse, and solve linear equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb41417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.477225575051661\n",
      "-2.0000000000000004\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(A))\n",
    "print(np.linalg.det(A))\n",
    "print(np.linalg.inv(A))\n",
    "print(np.linalg.solve(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ceea89",
   "metadata": {},
   "source": [
    "Now, we are able to construct the rest of matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89798724",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.25\n",
    "D = gamma * Z + V\n",
    "Y = beta * D + U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22223fcc",
   "metadata": {},
   "source": [
    "Sanity check: compute the mean, variance, and correlation between $U$ and $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f1fad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.026050794586944755\n",
      "-0.026050794586944755\n",
      "0.9736366557398173\n",
      "0.9736366557398173\n",
      "0.9891263962001459\n"
     ]
    }
   ],
   "source": [
    "print(U.sum() / U.size)\n",
    "print(U.mean())\n",
    "\n",
    "print(np.sqrt(((U - U.mean())**2).mean()))\n",
    "print(U.std())\n",
    "\n",
    "print((U @ V) / (np.linalg.norm(U) * np.linalg.norm(V)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f15c01",
   "metadata": {},
   "source": [
    "We can also compute the OLS and IV estimates: \n",
    "$$\\begin{aligned}\n",
    "    \\hat{\\beta}_{OLS} = (D'D)^{-1}(D'Y) \\\\\n",
    "    \\hat{\\beta}_{IV} = (Z'D)^{-1}(Z'Y)\n",
    "\\end{aligned}$$\n",
    "\n",
    "But before doing that, we want to _reshape_ our arrays (from 1d arrays to 2d arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74529dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58f85700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "D = D.reshape(N, 1)\n",
    "print(D.shape)\n",
    "\n",
    "Y = Y.reshape(N, 1)\n",
    "Z = Z.reshape(N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bd497",
   "metadata": {},
   "source": [
    "Get the OLS and IV estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16320bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93514913]]\n",
      "[[0.00804841]]\n"
     ]
    }
   ],
   "source": [
    "beta_ols = np.linalg.inv(D.transpose() @ D) @ (D.transpose() @ Y)\n",
    "print(beta_ols)\n",
    "beta_iv = np.linalg.inv(Z.transpose() @ D) @ (Z.transpose() @ Y)\n",
    "print(beta_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ee304",
   "metadata": {},
   "source": [
    "Recall that the the true value is 0. The IV estimate is very close to the true value while OLS is much more biased.\n",
    "\n",
    "One might argue that the result I showed above is just from one simulation. We should do the same simulation for several times and plot the whole distribution. And that's totally correct. Before doing this, we would like to introduce OOP. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237c30b",
   "metadata": {},
   "source": [
    "## Object-Oriented Programming (OOP)\n",
    "\n",
    "\n",
    "### What is OOP?\n",
    "\n",
    "OOP is a programming paradigm that focuses on the concept of classes and objects. It provides a mechanism to define new data structures with attributes and methods that are allowed only on the data structure you defined.\n",
    "\n",
    "- a class is the definition of a new data type.\n",
    "- objects are specific instances of that data type.\n",
    "\n",
    "\n",
    "### Why you should know about OOP? \n",
    "\n",
    "- OOP helps you abstract the problem and leads you to write reusable codes.\n",
    "- Understanding OOP can help you learn other packages faster (since they are usually designed based on OOP).\n",
    "    - NumPy: numpy.ndarray()\n",
    "    - Pandas: pandas.DataFrame()\n",
    "    - GeoPandas: geopandas.GeoDataFrame() (Thursday)\n",
    "    - Shapely: shaply.Polygon() (Thursday)\n",
    "    - BeautifulSoup: bs4.BeautifulSoup() (Friday) \n",
    "    - ScikitLearn: sklearn.linear_model.Lasso(), etc. \n",
    "- OOP is not a feature of Python. You can apply OOP in other langauges (MATLAB).\n",
    "\n",
    "### Let's apply OOP in building the simulation\n",
    "\n",
    "First, consider the simulation process:\n",
    "\n",
    "```\n",
    "for each iteration,\n",
    "    A data generator draws a sample (Y, D, Z)\n",
    "    An OLS estimator computes the OLS estimate using the sample data\n",
    "    An IV estimator computes the IV estimate using the sample data\n",
    "```\n",
    "\n",
    "The concept of a data generator and an estimator naturally emerge. As a result, we are going to construct this two classes: `DataGenerator` and `Estimator`. \n",
    "\n",
    "Let's start from `DataGenerator`. \n",
    "\n",
    "1. First, note that the data generating process can be uniquely determined by a few parameters in our model (i.e. $\\gamma$, $\\beta$, $\\sigma$, and $\\rho$). If two data generators have the same parameters, then we would not be able to distinguish them. These parameters are what we called **attributes** in OOP.\n",
    "2. Once we declare all the parameters, we can write a **method** that the object can use to draw a random sample $(Y_i, D_i, Z_i)$ of size $N$ from the data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09080109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self, gamma, beta, sigma, rho):\n",
    "        '''\n",
    "        Initiate a DataGenerator\n",
    "        '''\n",
    "        self.seed = 42\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.sigma = sigma\n",
    "        self.rho = rho\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "    def draw_sample(self, N):\n",
    "        '''\n",
    "        Draw a random sample of size N from the data generating process.\n",
    "        '''\n",
    "        Z = np.random.normal(0, self.sigma, N)\n",
    "        Sigma = np.array([[1, self.rho], [self.rho, 1]])\n",
    "        UV = np.random.multivariate_normal([0, 0], Sigma, N)\n",
    "        U = UV[:,0]\n",
    "        V = UV[:,1]\n",
    "        D = self.gamma * Z + V\n",
    "        Y = self.beta * D + U\n",
    "\n",
    "        Y = Y.reshape(N, 1)\n",
    "        D = D.reshape(N, 1)\n",
    "        Z = Z.reshape(N, 1)\n",
    "        \n",
    "        return (Y, D, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0895d",
   "metadata": {},
   "source": [
    "That's it! Now, let's construct an `DataGenerator` object and draw a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0754f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(gamma=0.25, beta=0, sigma=1, rho=0.99)\n",
    "Y, D, Z = data_generator.draw_sample(N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db275f3",
   "metadata": {},
   "source": [
    "Recall that the syntax of using a function was `f(a, b, c)`, which means that _we_ apply the function $f$ on $(a,b,c)$.\n",
    "\n",
    "Note that `DataGenerator.draw_sample` is called a **method** instead of a **function**. The syntax of using an object's method is `object.f(a, b)`, which means that the _object_ uses the method with $(a,b)$. In our setting, the data generator _draws_ a sample based on the input sample size $N$. We are really writing codes in human language with **subjects** and **verbs**!\n",
    "\n",
    "Now, let's construct the estimator object. Similarly we need to think about how we can describe the estimator. In this case, the most intuitive way is to specify whether we want to use the instrument or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4420ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    \n",
    "    def __init__(self, spec):\n",
    "        '''\n",
    "        Initiate an Estimator\n",
    "        '''\n",
    "        self.spec = spec\n",
    "            \n",
    "    def fit(self, Y, D, Z):\n",
    "        '''\n",
    "        Estimate the OLS or IV estimate\n",
    "        '''\n",
    "        assert Y.shape[0] == D.shape[0]\n",
    "        assert D.shape[0] == Z.shape[0]\n",
    "        \n",
    "        N = Y.shape[0] \n",
    "\n",
    "        if self.spec == \"OLS\":\n",
    "            beta = np.linalg.inv(D.transpose() @ D) @ (D.transpose() @ Y)\n",
    "            beta = beta[0,0]\n",
    "        elif self.spec == \"IV\":\n",
    "            beta = np.linalg.inv(Z.transpose() @ D) @ (Z.transpose() @ Y)\n",
    "            beta = beta[0,0]\n",
    "        else:\n",
    "            beta = None\n",
    "            \n",
    "        return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb81714",
   "metadata": {},
   "source": [
    "Let's create an OLS estimator and an IV estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aacab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9362273784887223 -0.06016958682084626\n"
     ]
    }
   ],
   "source": [
    "ols_estimator = Estimator(\"OLS\")\n",
    "iv_estimator = Estimator(\"IV\")\n",
    "beta_ols = ols_estimator.fit(Y, D, Z)\n",
    "beta_iv = iv_estimator.fit(Y, D, Z)\n",
    "print(beta_ols, beta_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e6913",
   "metadata": {},
   "source": [
    "Now, we are ready to convert the pseudo-code to real code and run some simulations. Recall that the pseudo-code was\n",
    "\n",
    "```\n",
    "for each iteration,\n",
    "    A data generator draws a sample (Y, D, Z)\n",
    "    An OLS estimator computes the OLS estimate using the sample data\n",
    "    An IV estimator computes the IV estimate using the sample data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef267b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(data_generator, ols_estimator, iv_estimator):\n",
    "    '''\n",
    "    Generate data using data_generator and output beta_ols and beta_iv\n",
    "    '''\n",
    "    Y, D, Z = data_generator.draw_sample(N=1000)\n",
    "    beta_ols = ols_estimator.fit(Y, D, Z)\n",
    "    beta_iv = iv_estimator.fit(Y, D, Z)\n",
    "    return (beta_ols, beta_iv)\n",
    "\n",
    "\n",
    "data_generator = DataGenerator(gamma=0.25, beta=0, sigma=1, rho=0.99)\n",
    "ols_estimator = Estimator(\"OLS\")\n",
    "iv_estimator = Estimator(\"IV\")\n",
    "\n",
    "M = 10000\n",
    "result_dict = {\"OLS\":[], \"IV\":[]}\n",
    "for _ in range(M):\n",
    "    beta_ols, beta_iv = simulation(data_generator, ols_estimator, iv_estimator)\n",
    "    result_dict[\"OLS\"].append(beta_ols)\n",
    "    result_dict[\"IV\"].append(beta_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9d874",
   "metadata": {},
   "source": [
    "Let's plot the density of OLS and IV estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95bcc095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.kdeplot(result_dict[\"OLS\"], label=\"OLS\")\n",
    "seaborn.kdeplot(result_dict[\"IV\"], label=f\"IV (gamma = {data_generator.gamma})\")\n",
    "plt.xlabel(\"beta\")\n",
    "plt.xlim([-1.5, 1.5]);\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc30ea",
   "metadata": {},
   "source": [
    "In practice, you probably do not need to build classes for running such a simple model; I picked a simple model just for illustrating the general idea of OOP. Just as a recap, we usually do the following:\n",
    "\n",
    "1. Build a **Dataset** object that collects all the relevant data required for estimation.\n",
    "2. Build an **Estimator** object that takes in the Dataset object and output the estimates.\n",
    "\n",
    "In fact, this workflow is very commonly used in our projects that involve estimating complex structural models using customized estimation strategies, (although we mainly use Matlab for this kind of projects.) \n",
    "\n",
    "Also in Python, usually you do not need to build your own dataset and estimator object. For instance:\n",
    "\n",
    "- `pandas.DataFrame` is the most commonly used dataset object\n",
    "- `scikit-learn` provides a lot of estimation objects such as `LASSO`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fdcb77",
   "metadata": {},
   "source": [
    "## Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ad8a1",
   "metadata": {},
   "source": [
    "Recall that our goal is to see how the distribution of $\\hat\\beta$ changes as $\\gamma$ changes. Currently, we only estimate the $\\hat\\beta$ for one single $\\gamma$. Let's implement this new simulation to compare IV estimates from different data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b04bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.25, 0.20, 0.15, 0.10, 0.05, 0.025, 0]\n",
    "generators = [DataGenerator(gamma=g, beta=0, sigma=1, rho=0.99) for g in gammas]\n",
    "\n",
    "def simulation(generator):\n",
    "    \n",
    "    M = 10000\n",
    "    gamma = generator.gamma\n",
    "    estimates = []\n",
    "    \n",
    "    for _ in range(M):\n",
    "        Y, D, Z = generator.draw_sample(N=1000)\n",
    "        beta_iv = iv_estimator.fit(Y, D, Z)\n",
    "        estimates.append(beta_iv)\n",
    "        \n",
    "    estimates = np.array(estimates)\n",
    "    return {\"gamma\": gamma, \"estimates\": estimates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360aa611",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "for generator in generators:\n",
    "    results.append(simulation(generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465d113",
   "metadata": {},
   "source": [
    "It took 11s to complete the simulation procedure. This is super slow. Can we do it faster?\n",
    "\n",
    "\n",
    "A key insight is that the whole simulation process for one $\\gamma$ value is completely independent of the simulation for another $\\gamma$. In scenarios like this, we should always consider _parallel computing_. The general idea is that, if the computation processes are independent, instead of running the computation on one computer, we should use several computers to compute them simultaneously.\n",
    "\n",
    "Parallel computing is a facinating subject itself, but because of the time constraint, I will focus on the `multiprocess` package. Specifically, I'll show how we can use this package to assign the simulation tasks for different gamma to different cores of the CPU and run simulations simultaneously.\n",
    "\n",
    "First, let's get the number of CPU cores we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c522655",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpu = multiprocess.cpu_count()\n",
    "n_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_process = min(len(gammas), n_cpu-1)\n",
    "num_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cf80f",
   "metadata": {},
   "source": [
    "We use the `multiprocess.Pool` class, which represents a pool of worker processes. We can use its `Pool.map(f, list)` method to evaluate `f` for all elements in `list`. Recall that we talked about the function `map` in the functional programming section of the last noteboook. This `Pool.map` function does the examly the same thing as `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c639b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with multiprocess.Pool(processes=num_process) as pool:\n",
    "    results = pool.map(simulation, generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9878283",
   "metadata": {},
   "source": [
    "It now takes less than 3 seconds to complete the simulation. You should always think about how to introduce multiprocessing whenever you are running a for-loop where the result of one iteration is independent of another one. This is especially important when you are planning to run the script on the server, since servers usually have much more cores than your laptop. For example, you may use 28 cores in one node on Acropolis.\n",
    "\n",
    "Finally, we are able to answer our question: how the distribution of $\\hat{\\beta}$ changes as we alter the magnitude of $\\gamma$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    gamma = result[\"gamma\"]\n",
    "    estimates = result[\"estimates\"]\n",
    "    estimates = estimates[(estimates >= -2) & (estimates <= 2)]\n",
    "    seaborn.kdeplot(estimates, label=f\"{gamma}\")\n",
    "plt.xlim([-2.5, 2.5]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145a458",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that as the strength of the first stage gets weaker, \n",
    "- the IV estimate becomes biased toward the OLS estimate;\n",
    "- the empirical distribution of the IV estimate is no longer bell-shaped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ac2cd",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- CMSC 12100 by Borja Sotomayor\n",
    "- ECON 31720 by Alexander Torgovitsky"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
